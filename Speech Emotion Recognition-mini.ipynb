{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description:\n",
    "- RAVDESS. This dataset includes around 1500 audio file input from 24 different actors. 12 male and 12 female where these actors record short audios in 8 different emotions i.e 1 = neutral, 2 = calm, 3 = happy, 4 = sad, 5 = angry, 6 = fearful, 7 = disgust, 8 = surprised.\n",
    "- Each audio file is named in such a way that the 7th character is consistent with the different emotions that they represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "#- Emotions to observe\n",
    "observed_emotions=['happy', 'sad', 'angry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob('speech-emotion-recognition-ravdess-data//Actor_*//*.wav'):\n",
    "    #for file in glob.glob(\"D:\\\\DataFlair\\\\ravdess data\\\\Actor_*\\\\*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    print(len(x))\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n"
     ]
    }
   ],
   "source": [
    "#- Split the dataset\n",
    "x_train,x_test,y_train,y_test=load_data(test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-635.539917</td>\n",
       "      <td>48.913681</td>\n",
       "      <td>-1.334187</td>\n",
       "      <td>9.256164</td>\n",
       "      <td>3.473320</td>\n",
       "      <td>-1.483662</td>\n",
       "      <td>-13.065701</td>\n",
       "      <td>-6.263948</td>\n",
       "      <td>-6.942184</td>\n",
       "      <td>4.532269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-595.491638</td>\n",
       "      <td>63.307995</td>\n",
       "      <td>-9.190067</td>\n",
       "      <td>18.133595</td>\n",
       "      <td>0.293340</td>\n",
       "      <td>-6.478998</td>\n",
       "      <td>-16.387072</td>\n",
       "      <td>-2.432556</td>\n",
       "      <td>0.271551</td>\n",
       "      <td>-6.522094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-415.265991</td>\n",
       "      <td>17.019833</td>\n",
       "      <td>-32.023663</td>\n",
       "      <td>-4.579306</td>\n",
       "      <td>-25.849531</td>\n",
       "      <td>-2.643941</td>\n",
       "      <td>-18.495287</td>\n",
       "      <td>-11.433888</td>\n",
       "      <td>-8.231014</td>\n",
       "      <td>-7.907068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-654.364929</td>\n",
       "      <td>55.947403</td>\n",
       "      <td>10.032094</td>\n",
       "      <td>14.811560</td>\n",
       "      <td>6.176264</td>\n",
       "      <td>4.364373</td>\n",
       "      <td>-4.320948</td>\n",
       "      <td>-2.160571</td>\n",
       "      <td>-4.422164</td>\n",
       "      <td>4.349211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-536.411194</td>\n",
       "      <td>37.881516</td>\n",
       "      <td>-24.262259</td>\n",
       "      <td>1.175580</td>\n",
       "      <td>-16.508852</td>\n",
       "      <td>-6.072886</td>\n",
       "      <td>-12.085666</td>\n",
       "      <td>-19.143553</td>\n",
       "      <td>-2.990855</td>\n",
       "      <td>-3.580963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>-405.639954</td>\n",
       "      <td>14.440585</td>\n",
       "      <td>-31.124907</td>\n",
       "      <td>-3.091275</td>\n",
       "      <td>-26.212135</td>\n",
       "      <td>-0.806042</td>\n",
       "      <td>-17.687391</td>\n",
       "      <td>-9.568361</td>\n",
       "      <td>-8.240066</td>\n",
       "      <td>-7.482601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>-590.579651</td>\n",
       "      <td>57.333092</td>\n",
       "      <td>-2.623664</td>\n",
       "      <td>17.550770</td>\n",
       "      <td>-2.282796</td>\n",
       "      <td>-14.932240</td>\n",
       "      <td>-7.920538</td>\n",
       "      <td>-10.666642</td>\n",
       "      <td>-6.124822</td>\n",
       "      <td>-5.736745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>-361.114990</td>\n",
       "      <td>43.840473</td>\n",
       "      <td>-23.039068</td>\n",
       "      <td>9.333183</td>\n",
       "      <td>-7.226469</td>\n",
       "      <td>-9.275711</td>\n",
       "      <td>-8.001760</td>\n",
       "      <td>-7.286619</td>\n",
       "      <td>-3.924150</td>\n",
       "      <td>1.859063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>-424.839478</td>\n",
       "      <td>40.239738</td>\n",
       "      <td>-16.835926</td>\n",
       "      <td>19.658031</td>\n",
       "      <td>-7.649911</td>\n",
       "      <td>-9.551789</td>\n",
       "      <td>-4.030232</td>\n",
       "      <td>-20.047182</td>\n",
       "      <td>-5.693709</td>\n",
       "      <td>0.380741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>-513.075134</td>\n",
       "      <td>17.246046</td>\n",
       "      <td>-19.095615</td>\n",
       "      <td>2.039681</td>\n",
       "      <td>-16.946220</td>\n",
       "      <td>-7.462149</td>\n",
       "      <td>-17.016466</td>\n",
       "      <td>-11.221250</td>\n",
       "      <td>-6.286739</td>\n",
       "      <td>-6.792493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows Ã— 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5    \\\n",
       "0   -635.539917  48.913681  -1.334187   9.256164   3.473320  -1.483662   \n",
       "1   -595.491638  63.307995  -9.190067  18.133595   0.293340  -6.478998   \n",
       "2   -415.265991  17.019833 -32.023663  -4.579306 -25.849531  -2.643941   \n",
       "3   -654.364929  55.947403  10.032094  14.811560   6.176264   4.364373   \n",
       "4   -536.411194  37.881516 -24.262259   1.175580 -16.508852  -6.072886   \n",
       "..          ...        ...        ...        ...        ...        ...   \n",
       "427 -405.639954  14.440585 -31.124907  -3.091275 -26.212135  -0.806042   \n",
       "428 -590.579651  57.333092  -2.623664  17.550770  -2.282796 -14.932240   \n",
       "429 -361.114990  43.840473 -23.039068   9.333183  -7.226469  -9.275711   \n",
       "430 -424.839478  40.239738 -16.835926  19.658031  -7.649911  -9.551789   \n",
       "431 -513.075134  17.246046 -19.095615   2.039681 -16.946220  -7.462149   \n",
       "\n",
       "           6          7         8         9    ...       170       171  \\\n",
       "0   -13.065701  -6.263948 -6.942184  4.532269  ...  0.000082  0.000118   \n",
       "1   -16.387072  -2.432556  0.271551 -6.522094  ...  0.000163  0.000073   \n",
       "2   -18.495287 -11.433888 -8.231014 -7.907068  ...  0.002161  0.001783   \n",
       "3    -4.320948  -2.160571 -4.422164  4.349211  ...  0.000013  0.000017   \n",
       "4   -12.085666 -19.143553 -2.990855 -3.580963  ...  0.000258  0.000175   \n",
       "..         ...        ...       ...       ...  ...       ...       ...   \n",
       "427 -17.687391  -9.568361 -8.240066 -7.482601  ...  0.001595  0.001436   \n",
       "428  -7.920538 -10.666642 -6.124822 -5.736745  ...  0.000068  0.000039   \n",
       "429  -8.001760  -7.286619 -3.924150  1.859063  ...  0.003026  0.003096   \n",
       "430  -4.030232 -20.047182 -5.693709  0.380741  ...  0.002696  0.002852   \n",
       "431 -17.016466 -11.221250 -6.286739 -6.792493  ...  0.001518  0.000885   \n",
       "\n",
       "          172       173       174       175       176       177       178  \\\n",
       "0    0.000074  0.000058  0.000070  0.000049  0.000052  0.000041  0.000013   \n",
       "1    0.000040  0.000021  0.000048  0.000052  0.000071  0.000068  0.000032   \n",
       "2    0.001656  0.001306  0.001037  0.001042  0.001067  0.000989  0.000779   \n",
       "3    0.000013  0.000009  0.000011  0.000019  0.000017  0.000005  0.000004   \n",
       "4    0.000279  0.000210  0.000106  0.000106  0.000141  0.000073  0.000030   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "427  0.001333  0.001338  0.001124  0.000888  0.000667  0.000467  0.000394   \n",
       "428  0.000047  0.000016  0.000014  0.000012  0.000007  0.000006  0.000006   \n",
       "429  0.004946  0.005072  0.006301  0.003938  0.003053  0.002635  0.001193   \n",
       "430  0.003253  0.001435  0.002909  0.002293  0.000912  0.000799  0.000458   \n",
       "431  0.000818  0.000575  0.000735  0.000541  0.000354  0.000495  0.000453   \n",
       "\n",
       "          179  \n",
       "0    0.000007  \n",
       "1    0.000018  \n",
       "2    0.000451  \n",
       "3    0.000002  \n",
       "4    0.000025  \n",
       "..        ...  \n",
       "427  0.000289  \n",
       "428  0.000008  \n",
       "429  0.000623  \n",
       "430  0.000240  \n",
       "431  0.000364  \n",
       "\n",
       "[432 rows x 180 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy    53\n",
       "sad      46\n",
       "angry    45\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432, 144)\n"
     ]
    }
   ],
   "source": [
    "#Get the shape of the training and testing datasets\n",
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.39%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36,  6,  3],\n",
       "       [ 5, 39,  9],\n",
       "       [ 1, 10, 35]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy    53\n",
       "sad      46\n",
       "angry    45\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7638888888888888"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(180, activation='relu', input_shape=(180,)))\n",
    "network.add(layers.Dense(10, activation='relu', input_shape=(180,)))\n",
    "network.add(layers.Dense(10, activation='relu', input_shape=(10,)))\n",
    "network.add(layers.Dense(10, activation='relu', input_shape=(10,)))\n",
    "network.add(layers.Dense(10, activation='relu', input_shape=(10,)))\n",
    "network.add(layers.Dense(10, activation='relu', input_shape=(10,)))\n",
    "network.add(layers.Dense(3, activation='softmax'))\n",
    "network.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 180)               32580     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1810      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 34,863\n",
      "Trainable params: 34,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = LabelEncoder().fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = LabelEncoder().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.1826 - accuracy: 0.3403\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.0589 - accuracy: 0.3866\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.9736 - accuracy: 0.5185\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.9218 - accuracy: 0.5255\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.9072 - accuracy: 0.5069\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.9335 - accuracy: 0.5301\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.9239 - accuracy: 0.5417\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.9744 - accuracy: 0.4144\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.9577 - accuracy: 0.4421\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.9333 - accuracy: 0.4468\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.9149 - accuracy: 0.5671\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.9139 - accuracy: 0.6134\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.8906 - accuracy: 0.5972\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.9236 - accuracy: 0.5370\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.9150 - accuracy: 0.5671\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.8930 - accuracy: 0.5810\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.8826 - accuracy: 0.5995\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.8580 - accuracy: 0.6157\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.8264 - accuracy: 0.6551\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.8517 - accuracy: 0.6111\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.8308 - accuracy: 0.6204\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.8046 - accuracy: 0.6319\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.8210 - accuracy: 0.6227\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.8306 - accuracy: 0.6019\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7734 - accuracy: 0.6806\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.8230 - accuracy: 0.6019\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.8549 - accuracy: 0.5394\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.8368 - accuracy: 0.5926\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.8639 - accuracy: 0.5486\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.8112 - accuracy: 0.6042\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7623 - accuracy: 0.6528\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7044 - accuracy: 0.7014\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7331 - accuracy: 0.6458\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7031 - accuracy: 0.7037\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.7014\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.7269\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.7245\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7239 - accuracy: 0.6528\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7319 - accuracy: 0.6551\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.7797 - accuracy: 0.6065\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7076 - accuracy: 0.7083\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7445 - accuracy: 0.6458\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.7289 - accuracy: 0.6458\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.7245\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.7060\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.7523\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7407\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6328 - accuracy: 0.7454\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5957 - accuracy: 0.7569\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.7407\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.7593\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.7022 - accuracy: 0.7176\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.7407\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.7315\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.7083\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6022 - accuracy: 0.7384\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6139 - accuracy: 0.7407\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5719 - accuracy: 0.7593\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5697 - accuracy: 0.7315\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.7477\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.6898\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6899 - accuracy: 0.6875\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.7384\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.7662\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.7477\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6530 - accuracy: 0.6898\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5562 - accuracy: 0.7731\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5344 - accuracy: 0.7870\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7431\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.5655 - accuracy: 0.7708\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5453 - accuracy: 0.7847\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6450 - accuracy: 0.6875\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5849 - accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.7361\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.7130\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5605 - accuracy: 0.7662\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7847\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7824\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7847\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7778\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7963\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.7546\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7731\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7801\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7662\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.8056\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.8102\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7963\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8032\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7917\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.8171\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8032\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7708\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.8218\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8287\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.8148\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.6991\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7917\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe6d532f9a0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(x_train, y_train, epochs=100, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6562 - accuracy: 0.7569\n",
      "test_acc: 0.7569444179534912 test_loss 0.6562196612358093\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(x_test, y_test)\n",
    "print('test_acc:', test_acc, 'test_loss', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x_test[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180,)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 192 files with happy emotion\n",
      "There are 192 files with angry emotion\n",
      "There are 192 files with sad emotion\n"
     ]
    }
   ],
   "source": [
    "happy =[]\n",
    "angry = []\n",
    "sad = []\n",
    "for file in glob.glob('speech-emotion-recognition-ravdess-data//Actor_*//*.wav'):\n",
    "    #for file in glob.glob(\"D:\\\\DataFlair\\\\ravdess data\\\\Actor_*\\\\*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        if emotion =='happy':\n",
    "            happy.append(file)\n",
    "        elif emotion=='angry':\n",
    "            angry.append(file)\n",
    "        elif emotion=='sad':\n",
    "            sad.append(file)\n",
    "            \n",
    "print(\"There are \"+str(len(happy))+\" files with happy emotion\")\n",
    "print(\"There are \"+str(len(angry))+\" files with angry emotion\")\n",
    "print(\"There are \"+str(len(sad))+\" files with sad emotion\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the predictions using model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select any file having happy emotion from list happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = happy[100]   ## selecting 100th file from happylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion happy\n"
     ]
    }
   ],
   "source": [
    "feat=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "temp = feat.reshape(1, 180)\n",
    "pred = np.argmax(network.predict(temp))\n",
    "emotions = {0:'angry',1:'happy',2:'sad'}\n",
    "print(\"Predicted Emotion \"+emotions[(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select any file having sad emotion from list sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sad[50]   ## selecting 50th file from happylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion sad\n"
     ]
    }
   ],
   "source": [
    "feat=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "temp = feat.reshape(1, 180)\n",
    "pred = np.argmax(network.predict(temp))\n",
    "emotions = {0:'angry',1:'happy',2:'sad'}\n",
    "print(\"Predicted Emotion \"+emotions[(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select any file having angry emotion from list angry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sad[75]   ## selecting 75th file from happylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion sad\n"
     ]
    }
   ],
   "source": [
    "feat=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "temp = feat.reshape(1, 180)\n",
    "pred = np.argmax(network.predict(temp))\n",
    "emotions = {0:'angry',1:'happy',2:'sad'}\n",
    "print(\"Predicted Emotion \"+emotions[(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that our model is able to identify the emotions in the audio files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
